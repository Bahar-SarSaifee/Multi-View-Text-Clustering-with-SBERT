{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343fdb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd147bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Dataset/BBC News.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b30aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330dd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.values[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e258b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(list(map(lambda x: 0 if x==\"business\" else 1 if x==\"tech\" else 2 if x==\"politics\" else 3 if x==\"sport\" else 4, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "model2 = SentenceTransformer('all-distilroberta-v1')\n",
    "\n",
    "model3 = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "model4 = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "model5 = SentenceTransformer('paraphrase-albert-small-v2')\n",
    "\n",
    "model6 = SentenceTransformer('paraphrase-MiniLM-L3-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_view_clustering(documents, num_views, num_clusters):\n",
    "    # Step 1: Vectorization for each view\n",
    "    views = []\n",
    "    for i in range(num_views):\n",
    "\n",
    "        if i == 0:\n",
    "            print(i)\n",
    "            embeddings = model1.encode(documents)\n",
    "        elif i == 1:\n",
    "            print(i)\n",
    "            embeddings = model2.encode(documents)\n",
    "        elif i == 2:\n",
    "            print(i)\n",
    "            embeddings = model3.encode(documents)\n",
    "        elif i == 3:\n",
    "            print(i)\n",
    "            embeddings = model4.encode(documents)\n",
    "        elif i == 4:\n",
    "            print(i)\n",
    "            embeddings = model5.encode(documents)\n",
    "        else:\n",
    "            print(i)\n",
    "            embeddings = model6.encode(documents)\n",
    "\n",
    "        views.append(embeddings)\n",
    "   \n",
    "    # Step 2: Apply K-means for each view\n",
    "    kmeans_models = []\n",
    "    for view in views:\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "        kmeans.fit(view)\n",
    "        kmeans_models.append(kmeans)\n",
    "\n",
    "        \n",
    "    # Step 3: Obtain cluster assignments for each document in each view\n",
    "    cluster_assignments = []\n",
    "    for i in range(num_views):\n",
    "        cluster_assignments.append(kmeans_models[i].labels_)\n",
    "        \n",
    "\n",
    "    # Step 4: Apply aggregation technique (selective voting) to obtain the final clusters\n",
    "    final_clusters = []\n",
    "    num_documents = len(documents)\n",
    "    for doc_index in range(num_documents):\n",
    "        votes = np.zeros(num_clusters)\n",
    "        for view_index in range(num_views):\n",
    "            cluster_index = cluster_assignments[view_index][doc_index]\n",
    "            votes[cluster_index] += 1\n",
    "        \n",
    "        # Apply selective voting\n",
    "        max_vote = np.max(votes)\n",
    "        max_clusters = np.where(votes == max_vote)[0]\n",
    "        if len(max_clusters) == 1:\n",
    "            # If there is a clear majority cluster, assign the document to that cluster\n",
    "            final_cluster = max_clusters[0]\n",
    "        else:\n",
    "            # If there is a tie or no clear majority, assign the document to a random cluster among the top-voted clusters\n",
    "            final_cluster = np.random.choice(max_clusters)\n",
    "        \n",
    "        final_clusters.append(final_cluster)\n",
    "\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075f521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "num_views = 6\n",
    "num_clusters = 5\n",
    "\n",
    "documents = df['Text']\n",
    "\n",
    "clusters = multi_view_clustering(documents, num_views, num_clusters)\n",
    "y_pred = clusters\n",
    "print(\"Cluster assignments:\", clusters[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F-measure:\")\n",
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1252c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    confusion_matrix = contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(confusion_matrix, axis=0)) / np.sum(confusion_matrix)\n",
    "\n",
    "# Report Purity Score\n",
    "purity = purity_score(y_true, y_pred)\n",
    "print(f\"The purity score is {round(purity*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6560c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
